{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3278, 50, 7)\n",
      "(3278, 3)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.024061918258666992\n",
      "Train on 2950 samples, validate on 328 samples\n",
      "Epoch 1/10\n",
      "2950/2950 [==============================] - 5s - loss: 0.0128 - val_loss: 0.0076\n",
      "Epoch 2/10\n",
      "2950/2950 [==============================] - 3s - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "2950/2950 [==============================] - 3s - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 4/10\n",
      "2950/2950 [==============================] - 3s - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 5/10\n",
      "2950/2950 [==============================] - 3s - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 6/10\n",
      "2950/2950 [==============================] - 3s - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 7/10\n",
      "2950/2950 [==============================] - 3s - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 8/10\n",
      "2950/2950 [==============================] - 3s - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 9/10\n",
      "2950/2950 [==============================] - 3s - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 10/10\n",
      "2950/2950 [==============================] - 4s - loss: 0.0015 - val_loss: 0.0015\n",
      "Training duration (s) :  43.51230597496033\n",
      "(3274, 50, 7)\n",
      "(3274, 7)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.02557373046875\n",
      "Train on 2946 samples, validate on 328 samples\n",
      "Epoch 1/10\n",
      "2946/2946 [==============================] - 5s - loss: 0.0129 - val_loss: 0.0084\n",
      "Epoch 2/10\n",
      "2946/2946 [==============================] - 4s - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 3/10\n",
      "2946/2946 [==============================] - 3s - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 4/10\n",
      "2946/2946 [==============================] - 3s - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 5/10\n",
      "2946/2946 [==============================] - 3s - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 6/10\n",
      "2946/2946 [==============================] - 3s - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 7/10\n",
      "2946/2946 [==============================] - 3s - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 8/10\n",
      "2946/2946 [==============================] - 3s - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "2946/2946 [==============================] - 3s - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "2946/2946 [==============================] - 3s - loss: 0.0020 - val_loss: 0.0023\n",
      "Training duration (s) :  41.88049912452698\n",
      "(3271, 50, 7)\n",
      "(3271, 10)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.02805328369140625\n",
      "Train on 2943 samples, validate on 328 samples\n",
      "Epoch 1/10\n",
      "2943/2943 [==============================] - 5s - loss: 0.0149 - val_loss: 0.0096\n",
      "Epoch 2/10\n",
      "2943/2943 [==============================] - 3s - loss: 0.0094 - val_loss: 0.0050\n",
      "Epoch 3/10\n",
      "2943/2943 [==============================] - 3s - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 4/10\n",
      "2943/2943 [==============================] - 3s - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 5/10\n",
      "2943/2943 [==============================] - 3s - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 6/10\n",
      "2943/2943 [==============================] - 3s - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 7/10\n",
      "2943/2943 [==============================] - 3s - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 8/10\n",
      "2943/2943 [==============================] - 3s - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "2943/2943 [==============================] - 3s - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "2943/2943 [==============================] - 3s - loss: 0.0025 - val_loss: 0.0021\n",
      "Training duration (s) :  41.861953020095825\n",
      "(3251, 50, 7)\n",
      "(3251, 30)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.025590181350708008\n",
      "Train on 2925 samples, validate on 326 samples\n",
      "Epoch 1/10\n",
      "2925/2925 [==============================] - 4s - loss: 0.0172 - val_loss: 0.0116\n",
      "Epoch 2/10\n",
      "2925/2925 [==============================] - 3s - loss: 0.0131 - val_loss: 0.0087\n",
      "Epoch 3/10\n",
      "2925/2925 [==============================] - 3s - loss: 0.0096 - val_loss: 0.0058\n",
      "Epoch 4/10\n",
      "2925/2925 [==============================] - 3s - loss: 0.0069 - val_loss: 0.0044\n",
      "Epoch 5/10\n",
      "2925/2925 [==============================] - 3s - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 6/10\n",
      "2925/2925 [==============================] - 3s - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "2925/2925 [==============================] - 3s - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "2925/2925 [==============================] - 3s - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "2925/2925 [==============================] - 3s - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "2925/2925 [==============================] - 3s - loss: 0.0045 - val_loss: 0.0034\n",
      "Training duration (s) :  41.933109521865845\n",
      "(3228, 100, 7)\n",
      "(3228, 3)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.026041746139526367\n",
      "Train on 2905 samples, validate on 323 samples\n",
      "Epoch 1/10\n",
      "2905/2905 [==============================] - 9s - loss: 0.0195 - val_loss: 0.0057\n",
      "Epoch 2/10\n",
      "2905/2905 [==============================] - 8s - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 3/10\n",
      "2905/2905 [==============================] - 10s - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 4/10\n",
      "2905/2905 [==============================] - 8s - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 5/10\n",
      "2905/2905 [==============================] - 8s - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 6/10\n",
      "2905/2905 [==============================] - 7s - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "2905/2905 [==============================] - 7s - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "2905/2905 [==============================] - 8s - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 9/10\n",
      "2905/2905 [==============================] - 7s - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "2905/2905 [==============================] - 7s - loss: 0.0017 - val_loss: 0.0013\n",
      "Training duration (s) :  91.63965463638306\n",
      "(3224, 100, 7)\n",
      "(3224, 7)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.2722482681274414\n",
      "Train on 2901 samples, validate on 323 samples\n",
      "Epoch 1/10\n",
      "2901/2901 [==============================] - 9s - loss: 0.0224 - val_loss: 0.0110\n",
      "Epoch 2/10\n",
      "2901/2901 [==============================] - 8s - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 3/10\n",
      "2901/2901 [==============================] - 8s - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 4/10\n",
      "2901/2901 [==============================] - 8s - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 5/10\n",
      "2901/2901 [==============================] - 8s - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 6/10\n",
      "2901/2901 [==============================] - 8s - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 7/10\n",
      "2901/2901 [==============================] - 8s - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 8/10\n",
      "2901/2901 [==============================] - 8s - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 9/10\n",
      "2901/2901 [==============================] - 8s - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "2901/2901 [==============================] - 8s - loss: 0.0024 - val_loss: 0.0019\n",
      "Training duration (s) :  91.53048872947693\n",
      "(3221, 100, 7)\n",
      "(3221, 10)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.025084733963012695\n",
      "Train on 2898 samples, validate on 323 samples\n",
      "Epoch 1/10\n",
      "2898/2898 [==============================] - 10s - loss: 0.0236 - val_loss: 0.0172\n",
      "Epoch 2/10\n",
      "2898/2898 [==============================] - 8s - loss: 0.0120 - val_loss: 0.0051\n",
      "Epoch 3/10\n",
      "2898/2898 [==============================] - 8s - loss: 0.0064 - val_loss: 0.0029\n",
      "Epoch 4/10\n",
      "2898/2898 [==============================] - 8s - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 5/10\n",
      "2898/2898 [==============================] - 8s - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 6/10\n",
      "2898/2898 [==============================] - 8s - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 7/10\n",
      "2898/2898 [==============================] - 8s - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 8/10\n",
      "2898/2898 [==============================] - 8s - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "2898/2898 [==============================] - 8s - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "2898/2898 [==============================] - 8s - loss: 0.0027 - val_loss: 0.0020\n",
      "Training duration (s) :  96.22992897033691\n",
      "(3201, 100, 7)\n",
      "(3201, 30)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.027594804763793945\n",
      "Train on 2880 samples, validate on 321 samples\n",
      "Epoch 1/10\n",
      "2880/2880 [==============================] - 10s - loss: 0.0299 - val_loss: 0.0217\n",
      "Epoch 2/10\n",
      "2880/2880 [==============================] - 8s - loss: 0.0206 - val_loss: 0.0116\n",
      "Epoch 3/10\n",
      "2880/2880 [==============================] - 8s - loss: 0.0114 - val_loss: 0.0057\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2880/2880 [==============================] - 8s - loss: 0.0075 - val_loss: 0.0051\n",
      "Epoch 5/10\n",
      "2880/2880 [==============================] - 8s - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 6/10\n",
      "2880/2880 [==============================] - 10s - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "2880/2880 [==============================] - 9s - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "2880/2880 [==============================] - 9s - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "2880/2880 [==============================] - 9s - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "2880/2880 [==============================] - 9s - loss: 0.0050 - val_loss: 0.0035\n",
      "Training duration (s) :  100.84111666679382\n",
      "(3289, 50, 7)\n",
      "(3289, 3)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.025568485260009766\n",
      "Train on 2960 samples, validate on 329 samples\n",
      "Epoch 1/10\n",
      "2960/2960 [==============================] - 6s - loss: 2.1506 - val_loss: 0.0142\n",
      "Epoch 2/10\n",
      "2960/2960 [==============================] - 4s - loss: 2.1092 - val_loss: 0.0068\n",
      "Epoch 3/10\n",
      "2960/2960 [==============================] - 4s - loss: 2.0893 - val_loss: 0.0075\n",
      "Epoch 4/10\n",
      "2960/2960 [==============================] - 4s - loss: 2.0472 - val_loss: 0.0056\n",
      "Epoch 5/10\n",
      "2960/2960 [==============================] - 4s - loss: 2.0060 - val_loss: 0.0043\n",
      "Epoch 6/10\n",
      "2960/2960 [==============================] - 4s - loss: 1.9798 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "2960/2960 [==============================] - 4s - loss: 1.9514 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "2960/2960 [==============================] - 4s - loss: 1.9542 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "2960/2960 [==============================] - 4s - loss: 1.8642 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "2960/2960 [==============================] - 4s - loss: 1.8688 - val_loss: 0.0033\n",
      "Training duration (s) :  51.95786952972412\n",
      "(3285, 50, 7)\n",
      "(3285, 7)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.026069164276123047\n",
      "Train on 2956 samples, validate on 329 samples\n",
      "Epoch 1/10\n",
      "2956/2956 [==============================] - 6s - loss: 2.1923 - val_loss: 0.0203\n",
      "Epoch 2/10\n",
      "2956/2956 [==============================] - 4s - loss: 2.1674 - val_loss: 0.0112\n",
      "Epoch 3/10\n",
      "2956/2956 [==============================] - 4s - loss: 2.1444 - val_loss: 0.0097\n",
      "Epoch 4/10\n",
      "2956/2956 [==============================] - 4s - loss: 2.1456 - val_loss: 0.0075\n",
      "Epoch 5/10\n",
      "2956/2956 [==============================] - 4s - loss: 2.1223 - val_loss: 0.0074\n",
      "Epoch 6/10\n",
      "2956/2956 [==============================] - 4s - loss: 2.0981 - val_loss: 0.0077\n",
      "Epoch 7/10\n",
      "2956/2956 [==============================] - 4s - loss: 2.0683 - val_loss: 0.0079\n",
      "Epoch 8/10\n",
      "2956/2956 [==============================] - 4s - loss: 2.0446 - val_loss: 0.0078\n",
      "Epoch 9/10\n",
      "2956/2956 [==============================] - 4s - loss: 2.0231 - val_loss: 0.0072\n",
      "Epoch 10/10\n",
      "2956/2956 [==============================] - 4s - loss: 2.0015 - val_loss: 0.0066\n",
      "Training duration (s) :  52.495218992233276\n",
      "(3282, 50, 7)\n",
      "(3282, 10)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.025066852569580078\n",
      "Train on 2953 samples, validate on 329 samples\n",
      "Epoch 1/10\n",
      "2953/2953 [==============================] - 6s - loss: 2.2297 - val_loss: 0.0172\n",
      "Epoch 2/10\n",
      "2953/2953 [==============================] - 4s - loss: 2.2138 - val_loss: 0.0082\n",
      "Epoch 3/10\n",
      "2953/2953 [==============================] - 4s - loss: 2.1964 - val_loss: 0.0084\n",
      "Epoch 4/10\n",
      "2953/2953 [==============================] - 4s - loss: 2.1689 - val_loss: 0.0052\n",
      "Epoch 5/10\n",
      "2953/2953 [==============================] - 4s - loss: 2.1528 - val_loss: 0.0064\n",
      "Epoch 6/10\n",
      "2953/2953 [==============================] - 4s - loss: 2.1439 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "2953/2953 [==============================] - 4s - loss: 2.0982 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "2953/2953 [==============================] - 4s - loss: 2.0687 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "2953/2953 [==============================] - 4s - loss: 2.0353 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "2953/2953 [==============================] - 4s - loss: 1.9995 - val_loss: 0.0049\n",
      "Training duration (s) :  54.69765257835388\n",
      "(3262, 50, 7)\n",
      "(3262, 30)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.025063514709472656\n",
      "Train on 2935 samples, validate on 327 samples\n",
      "Epoch 1/10\n",
      "2935/2935 [==============================] - 6s - loss: 2.3899 - val_loss: 0.0283\n",
      "Epoch 2/10\n",
      "2935/2935 [==============================] - 4s - loss: 2.3679 - val_loss: 0.0210\n",
      "Epoch 3/10\n",
      "2935/2935 [==============================] - 4s - loss: 2.3501 - val_loss: 0.0161\n",
      "Epoch 4/10\n",
      "2935/2935 [==============================] - 4s - loss: 2.3342 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "2935/2935 [==============================] - 4s - loss: 2.3215 - val_loss: 0.0124\n",
      "Epoch 6/10\n",
      "2935/2935 [==============================] - 4s - loss: 2.3197 - val_loss: 0.0123\n",
      "Epoch 7/10\n",
      "2935/2935 [==============================] - 4s - loss: 2.2847 - val_loss: 0.0118\n",
      "Epoch 8/10\n",
      "2935/2935 [==============================] - 4s - loss: 2.2560 - val_loss: 0.0110\n",
      "Epoch 9/10\n",
      "2935/2935 [==============================] - 4s - loss: 2.2241 - val_loss: 0.0104\n",
      "Epoch 10/10\n",
      "2935/2935 [==============================] - 4s - loss: 2.1909 - val_loss: 0.0102\n",
      "Training duration (s) :  55.76771688461304\n",
      "(3239, 100, 7)\n",
      "(3239, 3)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.025041580200195312\n",
      "Train on 2915 samples, validate on 324 samples\n",
      "Epoch 1/10\n",
      "2915/2915 [==============================] - 12s - loss: 0.0334 - val_loss: 23.5844\n",
      "Epoch 2/10\n",
      "2915/2915 [==============================] - 10s - loss: 0.0108 - val_loss: 23.4531\n",
      "Epoch 3/10\n",
      "2915/2915 [==============================] - 10s - loss: 0.0074 - val_loss: 23.5345\n",
      "Epoch 4/10\n",
      "2915/2915 [==============================] - 10s - loss: 0.0067 - val_loss: 23.5118\n",
      "Epoch 5/10\n",
      "2915/2915 [==============================] - 10s - loss: 0.0057 - val_loss: 23.4846\n",
      "Epoch 6/10\n",
      "2915/2915 [==============================] - 10s - loss: 0.0054 - val_loss: 23.4920\n",
      "Epoch 7/10\n",
      "2915/2915 [==============================] - 10s - loss: 0.0049 - val_loss: 23.4880\n",
      "Epoch 8/10\n",
      "2915/2915 [==============================] - 11s - loss: 0.0052 - val_loss: 23.4713\n",
      "Epoch 9/10\n",
      "2915/2915 [==============================] - 11s - loss: 0.0045 - val_loss: 23.4743\n",
      "Epoch 10/10\n",
      "2915/2915 [==============================] - 11s - loss: 0.0046 - val_loss: 23.4787\n",
      "Training duration (s) :  118.51718235015869\n",
      "(3235, 100, 7)\n",
      "(3235, 7)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.02860260009765625\n",
      "Train on 2911 samples, validate on 324 samples\n",
      "Epoch 1/10\n",
      "2911/2911 [==============================] - 13s - loss: 2.7048 - val_loss: 0.0217\n",
      "Epoch 2/10\n",
      "2911/2911 [==============================] - 11s - loss: 2.6693 - val_loss: 0.0100\n",
      "Epoch 3/10\n",
      "2911/2911 [==============================] - 11s - loss: 2.6559 - val_loss: 0.0071\n",
      "Epoch 4/10\n",
      "2911/2911 [==============================] - 11s - loss: 2.6244 - val_loss: 0.0076\n",
      "Epoch 5/10\n",
      "2911/2911 [==============================] - 11s - loss: 2.5911 - val_loss: 0.0064\n",
      "Epoch 6/10\n",
      "2911/2911 [==============================] - 11s - loss: 2.5607 - val_loss: 0.0074\n",
      "Epoch 7/10\n",
      "2911/2911 [==============================] - 11s - loss: 2.5465 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "2911/2911 [==============================] - 12s - loss: 2.4944 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "2911/2911 [==============================] - 12s - loss: 2.4634 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "2911/2911 [==============================] - 12s - loss: 2.4055 - val_loss: 0.0039\n",
      "Training duration (s) :  128.80502843856812\n",
      "(3232, 100, 7)\n",
      "(3232, 10)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.02606940269470215\n",
      "Train on 2908 samples, validate on 324 samples\n",
      "Epoch 1/10\n",
      "2908/2908 [==============================] - 14s - loss: 2.5439 - val_loss: 0.0316\n",
      "Epoch 2/10\n",
      "2908/2908 [==============================] - 12s - loss: 2.5066 - val_loss: 0.0107\n",
      "Epoch 3/10\n",
      "2908/2908 [==============================] - 12s - loss: 2.4782 - val_loss: 0.0080\n",
      "Epoch 4/10\n",
      "2908/2908 [==============================] - 13s - loss: 2.4657 - val_loss: 0.0069\n",
      "Epoch 5/10\n",
      "2908/2908 [==============================] - 12s - loss: 2.4267 - val_loss: 0.0072\n",
      "Epoch 6/10\n",
      "2908/2908 [==============================] - 12s - loss: 2.4056 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "2908/2908 [==============================] - 12s - loss: 2.3592 - val_loss: 0.0062\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2908/2908 [==============================] - 12s - loss: 2.3642 - val_loss: 0.0061\n",
      "Epoch 9/10\n",
      "2908/2908 [==============================] - 12s - loss: 2.3126 - val_loss: 0.0060\n",
      "Epoch 10/10\n",
      "2908/2908 [==============================] - 12s - loss: 2.2851 - val_loss: 0.0059\n",
      "Training duration (s) :  138.4932246208191\n",
      "(3212, 100, 7)\n",
      "(3212, 30)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.026589632034301758\n",
      "Train on 2890 samples, validate on 322 samples\n",
      "Epoch 1/10\n",
      "2890/2890 [==============================] - 15s - loss: 2.3342 - val_loss: 0.0400\n",
      "Epoch 2/10\n",
      "2890/2890 [==============================] - 13s - loss: 2.2954 - val_loss: 0.0237\n",
      "Epoch 3/10\n",
      "2890/2890 [==============================] - 13s - loss: 2.2894 - val_loss: 0.0175\n",
      "Epoch 4/10\n",
      "2890/2890 [==============================] - 13s - loss: 2.2668 - val_loss: 0.0151\n",
      "Epoch 5/10\n",
      "2890/2890 [==============================] - 13s - loss: 2.2479 - val_loss: 0.0141\n",
      "Epoch 6/10\n",
      "2890/2890 [==============================] - 13s - loss: 2.2195 - val_loss: 0.0126\n",
      "Epoch 7/10\n",
      "2890/2890 [==============================] - 13s - loss: 2.2112 - val_loss: 0.0121\n",
      "Epoch 8/10\n",
      "2890/2890 [==============================] - 13s - loss: 2.1884 - val_loss: 0.0113\n",
      "Epoch 9/10\n",
      "2890/2890 [==============================] - 13s - loss: 2.1302 - val_loss: 0.0116\n",
      "Epoch 10/10\n",
      "2890/2890 [==============================] - 13s - loss: 2.1207 - val_loss: 0.0109\n",
      "Training duration (s) :  144.52861332893372\n",
      "(3289, 50, 7)\n",
      "(3289, 3)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.026543617248535156\n",
      "Train on 2960 samples, validate on 329 samples\n",
      "Epoch 1/10\n",
      "2960/2960 [==============================] - 10s - loss: 0.0107 - val_loss: 0.0064\n",
      "Epoch 2/10\n",
      "2960/2960 [==============================] - 7s - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "2960/2960 [==============================] - 6s - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 4/10\n",
      "2960/2960 [==============================] - 7s - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 5/10\n",
      "2960/2960 [==============================] - 6s - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 6/10\n",
      "2960/2960 [==============================] - 6s - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 7/10\n",
      "2960/2960 [==============================] - 7s - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "2960/2960 [==============================] - 6s - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "2960/2960 [==============================] - 7s - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 10/10\n",
      "2960/2960 [==============================] - 6s - loss: 0.0016 - val_loss: 0.0013\n",
      "Training duration (s) :  78.95211863517761\n",
      "(3285, 50, 7)\n",
      "(3285, 7)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.030579805374145508\n",
      "Train on 2956 samples, validate on 329 samples\n",
      "Epoch 1/10\n",
      "2956/2956 [==============================] - 9s - loss: 0.0109 - val_loss: 0.0071\n",
      "Epoch 2/10\n",
      "2956/2956 [==============================] - 6s - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 3/10\n",
      "2956/2956 [==============================] - 6s - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 4/10\n",
      "2956/2956 [==============================] - 6s - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 5/10\n",
      "2956/2956 [==============================] - 6s - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 6/10\n",
      "2956/2956 [==============================] - 6s - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 7/10\n",
      "2956/2956 [==============================] - 6s - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 8/10\n",
      "2956/2956 [==============================] - 6s - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 9/10\n",
      "2956/2956 [==============================] - 6s - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "2956/2956 [==============================] - 6s - loss: 0.0020 - val_loss: 0.0018\n",
      "Training duration (s) :  77.61048793792725\n",
      "(3282, 50, 7)\n",
      "(3282, 10)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.024065494537353516\n",
      "Train on 2953 samples, validate on 329 samples\n",
      "Epoch 1/10\n",
      "2953/2953 [==============================] - 10s - loss: 0.0110 - val_loss: 0.0067\n",
      "Epoch 2/10\n",
      "2953/2953 [==============================] - 7s - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 3/10\n",
      "2953/2953 [==============================] - 7s - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 4/10\n",
      "2953/2953 [==============================] - 7s - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 5/10\n",
      "2953/2953 [==============================] - 7s - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 6/10\n",
      "2953/2953 [==============================] - 7s - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 7/10\n",
      "2953/2953 [==============================] - 7s - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 8/10\n",
      "2953/2953 [==============================] - 7s - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "2953/2953 [==============================] - 7s - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "2953/2953 [==============================] - 7s - loss: 0.0022 - val_loss: 0.0019\n",
      "Training duration (s) :  84.68082523345947\n",
      "(3262, 50, 7)\n",
      "(3262, 30)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.023575544357299805\n",
      "Train on 2935 samples, validate on 327 samples\n",
      "Epoch 1/10\n",
      "2935/2935 [==============================] - 11s - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 2/10\n",
      "2935/2935 [==============================] - 7s - loss: 0.0097 - val_loss: 0.0074\n",
      "Epoch 3/10\n",
      "2935/2935 [==============================] - 7s - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 4/10\n",
      "2935/2935 [==============================] - 7s - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 5/10\n",
      "2935/2935 [==============================] - 7s - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 6/10\n",
      "2935/2935 [==============================] - 7s - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "2935/2935 [==============================] - 7s - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "2935/2935 [==============================] - 7s - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "2935/2935 [==============================] - 7s - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "2935/2935 [==============================] - 7s - loss: 0.0040 - val_loss: 0.0034\n",
      "Training duration (s) :  89.05605673789978\n",
      "(3239, 100, 7)\n",
      "(3239, 3)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.02556777000427246\n",
      "Train on 2915 samples, validate on 324 samples\n",
      "Epoch 1/10\n",
      "2915/2915 [==============================] - 19s - loss: 0.0136 - val_loss: 0.0066\n",
      "Epoch 2/10\n",
      "2915/2915 [==============================] - 16s - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 3/10\n",
      "2915/2915 [==============================] - 17s - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 4/10\n",
      "2915/2915 [==============================] - 17s - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 5/10\n",
      "2915/2915 [==============================] - 17s - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 6/10\n",
      "2915/2915 [==============================] - 17s - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 7/10\n",
      "2915/2915 [==============================] - 17s - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 8/10\n",
      "2915/2915 [==============================] - 17s - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "2915/2915 [==============================] - 17s - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "2915/2915 [==============================] - 17s - loss: 0.0019 - val_loss: 0.0021\n",
      "Training duration (s) :  185.14723563194275\n",
      "(3235, 100, 7)\n",
      "(3235, 7)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.02606940269470215\n",
      "Train on 2911 samples, validate on 324 samples\n",
      "Epoch 1/10\n",
      "2911/2911 [==============================] - 22s - loss: 0.0147 - val_loss: 0.0072\n",
      "Epoch 2/10\n",
      "2911/2911 [==============================] - 19s - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 3/10\n",
      "2911/2911 [==============================] - 19s - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 4/10\n",
      "2911/2911 [==============================] - 19s - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 5/10\n",
      "2911/2911 [==============================] - 19s - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 6/10\n",
      "2911/2911 [==============================] - 19s - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "2911/2911 [==============================] - 20s - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 8/10\n",
      "2911/2911 [==============================] - 19s - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 9/10\n",
      "2911/2911 [==============================] - 19s - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "2911/2911 [==============================] - 20s - loss: 0.0023 - val_loss: 0.0018\n",
      "Training duration (s) :  209.74287247657776\n",
      "(3232, 100, 7)\n",
      "(3232, 10)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.02656841278076172\n",
      "Train on 2908 samples, validate on 324 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2908/2908 [==============================] - 25s - loss: 0.0191 - val_loss: 0.0119\n",
      "Epoch 2/10\n",
      "2908/2908 [==============================] - 22s - loss: 0.0097 - val_loss: 0.0048\n",
      "Epoch 3/10\n",
      "2908/2908 [==============================] - 22s - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 4/10\n",
      "2908/2908 [==============================] - 22s - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 5/10\n",
      "2908/2908 [==============================] - 23s - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 6/10\n",
      "2908/2908 [==============================] - 23s - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 7/10\n",
      "2908/2908 [==============================] - 23s - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 8/10\n",
      "2908/2908 [==============================] - 23s - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 9/10\n",
      "2908/2908 [==============================] - 23s - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "2908/2908 [==============================] - 23s - loss: 0.0027 - val_loss: 0.0018\n",
      "Training duration (s) :  242.40105605125427\n",
      "(3212, 100, 7)\n",
      "(3212, 30)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.026069164276123047\n",
      "Train on 2890 samples, validate on 322 samples\n",
      "Epoch 1/10\n",
      "2890/2890 [==============================] - 27s - loss: 0.0202 - val_loss: 0.0137\n",
      "Epoch 2/10\n",
      "2890/2890 [==============================] - 24s - loss: 0.0118 - val_loss: 0.0067\n",
      "Epoch 3/10\n",
      "2890/2890 [==============================] - 24s - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 4/10\n",
      "2890/2890 [==============================] - 24s - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 5/10\n",
      "2890/2890 [==============================] - 24s - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 6/10\n",
      "2890/2890 [==============================] - 24s - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "2890/2890 [==============================] - 24s - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "2890/2890 [==============================] - 24s - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "2890/2890 [==============================] - 24s - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "2890/2890 [==============================] - 24s - loss: 0.0042 - val_loss: 0.0035\n",
      "Training duration (s) :  258.177508354187\n",
      "(3283, 50, 7)\n",
      "(3283, 3)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.03058147430419922\n",
      "Train on 2954 samples, validate on 329 samples\n",
      "Epoch 1/10\n",
      "2954/2954 [==============================] - 18s - loss: 0.8878 - val_loss: 0.0112\n",
      "Epoch 2/10\n",
      "2954/2954 [==============================] - 15s - loss: 0.8668 - val_loss: 0.0063\n",
      "Epoch 3/10\n",
      "2954/2954 [==============================] - 15s - loss: 0.8554 - val_loss: 0.0050\n",
      "Epoch 4/10\n",
      "2954/2954 [==============================] - 15s - loss: 0.8310 - val_loss: 0.0049\n",
      "Epoch 5/10\n",
      "2954/2954 [==============================] - 15s - loss: 0.8180 - val_loss: 0.0039\n",
      "Epoch 6/10\n",
      "2954/2954 [==============================] - 15s - loss: 0.8134 - val_loss: 0.0033\n",
      "Epoch 7/10\n",
      "2954/2954 [==============================] - 15s - loss: 0.7704 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "2954/2954 [==============================] - 15s - loss: 0.7572 - val_loss: 0.0033\n",
      "Epoch 9/10\n",
      "2954/2954 [==============================] - 15s - loss: 0.7531 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "2954/2954 [==============================] - 14s - loss: 0.7115 - val_loss: 0.0030\n",
      "Training duration (s) :  162.166672706604\n",
      "(3279, 50, 7)\n",
      "(3279, 7)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.024064302444458008\n",
      "Train on 2951 samples, validate on 328 samples\n",
      "Epoch 1/10\n",
      "2951/2951 [==============================] - 19s - loss: 0.8457 - val_loss: 0.0180\n",
      "Epoch 2/10\n",
      "2951/2951 [==============================] - 15s - loss: 0.8215 - val_loss: 0.0099\n",
      "Epoch 3/10\n",
      "2951/2951 [==============================] - 15s - loss: 0.8130 - val_loss: 0.0063\n",
      "Epoch 4/10\n",
      "2951/2951 [==============================] - 15s - loss: 0.8011 - val_loss: 0.0068\n",
      "Epoch 5/10\n",
      "2951/2951 [==============================] - 15s - loss: 0.7811 - val_loss: 0.0057\n",
      "Epoch 6/10\n",
      "2951/2951 [==============================] - 15s - loss: 0.7728 - val_loss: 0.0057\n",
      "Epoch 7/10\n",
      "2951/2951 [==============================] - 15s - loss: 0.7556 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "2951/2951 [==============================] - 15s - loss: 0.7388 - val_loss: 0.0059\n",
      "Epoch 9/10\n",
      "2951/2951 [==============================] - 15s - loss: 0.7168 - val_loss: 0.0056\n",
      "Epoch 10/10\n",
      "2951/2951 [==============================] - 15s - loss: 0.7126 - val_loss: 0.0047\n",
      "Training duration (s) :  168.37117886543274\n",
      "(3276, 50, 7)\n",
      "(3276, 10)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.028600454330444336\n",
      "Train on 2948 samples, validate on 328 samples\n",
      "Epoch 1/10\n",
      "2948/2948 [==============================] - 20s - loss: 0.0247 - val_loss: 7.2299\n",
      "Epoch 2/10\n",
      "2948/2948 [==============================] - 16s - loss: 0.0157 - val_loss: 7.2018\n",
      "Epoch 3/10\n",
      "2948/2948 [==============================] - 16s - loss: 0.0096 - val_loss: 7.1701\n",
      "Epoch 4/10\n",
      "2948/2948 [==============================] - 16s - loss: 0.0078 - val_loss: 7.1774\n",
      "Epoch 5/10\n",
      "2948/2948 [==============================] - 16s - loss: 0.0069 - val_loss: 7.1759\n",
      "Epoch 6/10\n",
      "2948/2948 [==============================] - 16s - loss: 0.0062 - val_loss: 7.1644\n",
      "Epoch 7/10\n",
      "2948/2948 [==============================] - 16s - loss: 0.0060 - val_loss: 7.1612\n",
      "Epoch 8/10\n",
      "2948/2948 [==============================] - 16s - loss: 0.0058 - val_loss: 7.1667\n",
      "Epoch 9/10\n",
      "2948/2948 [==============================] - 16s - loss: 0.0055 - val_loss: 7.1668\n",
      "Epoch 10/10\n",
      "2948/2948 [==============================] - 16s - loss: 0.0053 - val_loss: 7.1609\n",
      "Training duration (s) :  177.2598114013672\n",
      "(3256, 50, 7)\n",
      "(3256, 30)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.02704906463623047\n",
      "Train on 2930 samples, validate on 326 samples\n",
      "Epoch 1/10\n",
      "2930/2930 [==============================] - 19s - loss: 0.8806 - val_loss: 0.0208\n",
      "Epoch 2/10\n",
      "2930/2930 [==============================] - 16s - loss: 0.8661 - val_loss: 0.0157\n",
      "Epoch 3/10\n",
      "2930/2930 [==============================] - 16s - loss: 0.8554 - val_loss: 0.0116\n",
      "Epoch 4/10\n",
      "2930/2930 [==============================] - 16s - loss: 0.8503 - val_loss: 0.0115\n",
      "Epoch 5/10\n",
      "2930/2930 [==============================] - 16s - loss: 0.8314 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "2930/2930 [==============================] - 16s - loss: 0.8237 - val_loss: 0.0090\n",
      "Epoch 7/10\n",
      "2930/2930 [==============================] - 16s - loss: 0.8067 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "2930/2930 [==============================] - 16s - loss: 0.7947 - val_loss: 0.0084\n",
      "Epoch 9/10\n",
      "2930/2930 [==============================] - 16s - loss: 0.7759 - val_loss: 0.0084\n",
      "Epoch 10/10\n",
      "2930/2930 [==============================] - 16s - loss: 0.7652 - val_loss: 0.0081\n",
      "Training duration (s) :  175.88614630699158\n",
      "(3233, 100, 7)\n",
      "(3233, 3)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.028575897216796875\n",
      "Train on 2909 samples, validate on 324 samples\n",
      "Epoch 1/10\n",
      "2909/2909 [==============================] - 35s - loss: 0.5503 - val_loss: 0.0197\n",
      "Epoch 2/10\n",
      "2909/2909 [==============================] - 31s - loss: 0.5250 - val_loss: 0.0068\n",
      "Epoch 3/10\n",
      "2909/2909 [==============================] - 31s - loss: 0.5154 - val_loss: 0.0070\n",
      "Epoch 4/10\n",
      "2909/2909 [==============================] - 31s - loss: 0.5081 - val_loss: 0.0050\n",
      "Epoch 5/10\n",
      "2909/2909 [==============================] - 31s - loss: 0.4927 - val_loss: 0.0048\n",
      "Epoch 6/10\n",
      "2909/2909 [==============================] - 32s - loss: 0.4731 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "2909/2909 [==============================] - 32s - loss: 0.4689 - val_loss: 0.0068\n",
      "Epoch 8/10\n",
      "2909/2909 [==============================] - 32s - loss: 0.4470 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "2909/2909 [==============================] - 32s - loss: 0.4184 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "2909/2909 [==============================] - 32s - loss: 0.4107 - val_loss: 0.0037\n",
      "Training duration (s) :  332.4448947906494\n",
      "(3229, 100, 7)\n",
      "(3229, 7)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.024064302444458008\n",
      "Train on 2906 samples, validate on 323 samples\n",
      "Epoch 1/10\n",
      "2906/2906 [==============================] - 37s - loss: 0.5690 - val_loss: 0.0199\n",
      "Epoch 2/10\n",
      "2906/2906 [==============================] - 33s - loss: 0.5375 - val_loss: 0.0087\n",
      "Epoch 3/10\n",
      "2906/2906 [==============================] - 33s - loss: 0.5268 - val_loss: 0.0065\n",
      "Epoch 4/10\n",
      "2906/2906 [==============================] - 33s - loss: 0.5191 - val_loss: 0.0068\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2906/2906 [==============================] - 34s - loss: 0.5012 - val_loss: 0.0055\n",
      "Epoch 6/10\n",
      "2906/2906 [==============================] - 34s - loss: 0.4916 - val_loss: 0.0047\n",
      "Epoch 7/10\n",
      "2906/2906 [==============================] - 34s - loss: 0.4784 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "2906/2906 [==============================] - 34s - loss: 0.4578 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "2906/2906 [==============================] - 34s - loss: 0.4481 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "2906/2906 [==============================] - 34s - loss: 0.4181 - val_loss: 0.0055\n",
      "Training duration (s) :  354.45124101638794\n",
      "(3226, 100, 7)\n",
      "(3226, 10)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.024065017700195312\n",
      "Train on 2903 samples, validate on 323 samples\n",
      "Epoch 1/10\n",
      "2903/2903 [==============================] - 40s - loss: 0.5884 - val_loss: 0.0344\n",
      "Epoch 2/10\n",
      "2903/2903 [==============================] - 36s - loss: 0.5635 - val_loss: 0.0168\n",
      "Epoch 3/10\n",
      "2903/2903 [==============================] - 36s - loss: 0.5415 - val_loss: 0.0097\n",
      "Epoch 4/10\n",
      "2903/2903 [==============================] - 37s - loss: 0.5326 - val_loss: 0.0079\n",
      "Epoch 5/10\n",
      "2903/2903 [==============================] - 37s - loss: 0.5199 - val_loss: 0.0063\n",
      "Epoch 6/10\n",
      "2903/2903 [==============================] - 37s - loss: 0.5125 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "2903/2903 [==============================] - 38s - loss: 0.4938 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "2903/2903 [==============================] - 38s - loss: 0.4850 - val_loss: 0.0065\n",
      "Epoch 9/10\n",
      "2903/2903 [==============================] - 38s - loss: 0.4716 - val_loss: 0.0057\n",
      "Epoch 10/10\n",
      "2903/2903 [==============================] - 37s - loss: 0.4583 - val_loss: 0.0053\n",
      "Training duration (s) :  388.0989832878113\n",
      "(3206, 100, 7)\n",
      "(3206, 30)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.027573585510253906\n",
      "Train on 2885 samples, validate on 321 samples\n",
      "Epoch 1/10\n",
      "2885/2885 [==============================] - 41s - loss: 0.6451 - val_loss: 0.0436\n",
      "Epoch 2/10\n",
      "2885/2885 [==============================] - 37s - loss: 0.6211 - val_loss: 0.0224\n",
      "Epoch 3/10\n",
      "2885/2885 [==============================] - 37s - loss: 0.6019 - val_loss: 0.0141\n",
      "Epoch 4/10\n",
      "2885/2885 [==============================] - 38s - loss: 0.5880 - val_loss: 0.0127\n",
      "Epoch 5/10\n",
      "2885/2885 [==============================] - 37s - loss: 0.5731 - val_loss: 0.0118\n",
      "Epoch 6/10\n",
      "2885/2885 [==============================] - 38s - loss: 0.5634 - val_loss: 0.0123\n",
      "Epoch 7/10\n",
      "2885/2885 [==============================] - 37s - loss: 0.5528 - val_loss: 0.0114\n",
      "Epoch 8/10\n",
      "2885/2885 [==============================] - 38s - loss: 0.5323 - val_loss: 0.0108\n",
      "Epoch 9/10\n",
      "2885/2885 [==============================] - 38s - loss: 0.5261 - val_loss: 0.0106\n",
      "Epoch 10/10\n",
      "2885/2885 [==============================] - 38s - loss: 0.4967 - val_loss: 0.0100\n",
      "Training duration (s) :  394.97345542907715\n",
      "(3289, 50, 7)\n",
      "(3289, 3)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.026570796966552734\n",
      "Train on 2960 samples, validate on 329 samples\n",
      "Epoch 1/10\n",
      "2960/2960 [==============================] - 27s - loss: 0.0253 - val_loss: 0.0155\n",
      "Epoch 2/10\n",
      "2960/2960 [==============================] - 22s - loss: 0.0117 - val_loss: 0.0069\n",
      "Epoch 3/10\n",
      "2960/2960 [==============================] - 22s - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 4/10\n",
      "2960/2960 [==============================] - 22s - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 5/10\n",
      "2960/2960 [==============================] - 22s - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 6/10\n",
      "2960/2960 [==============================] - 22s - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "2960/2960 [==============================] - 22s - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "2960/2960 [==============================] - 22s - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "2960/2960 [==============================] - 22s - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "2960/2960 [==============================] - 22s - loss: 0.0038 - val_loss: 0.0039\n",
      "Training duration (s) :  238.89107179641724\n",
      "(3285, 50, 7)\n",
      "(3285, 7)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.02707219123840332\n",
      "Train on 2956 samples, validate on 329 samples\n",
      "Epoch 1/10\n",
      "2956/2956 [==============================] - 28s - loss: 0.0276 - val_loss: 0.0174\n",
      "Epoch 2/10\n",
      "2956/2956 [==============================] - 23s - loss: 0.0158 - val_loss: 0.0086\n",
      "Epoch 3/10\n",
      "2956/2956 [==============================] - 23s - loss: 0.0097 - val_loss: 0.0061\n",
      "Epoch 4/10\n",
      "2956/2956 [==============================] - 23s - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 5/10\n",
      "2956/2956 [==============================] - 23s - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "2956/2956 [==============================] - 23s - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "2956/2956 [==============================] - 23s - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "2956/2956 [==============================] - 23s - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "2956/2956 [==============================] - 23s - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "2956/2956 [==============================] - 23s - loss: 0.0053 - val_loss: 0.0040\n",
      "Training duration (s) :  248.60627818107605\n",
      "(3282, 50, 7)\n",
      "(3282, 10)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.02606654167175293\n",
      "Train on 2953 samples, validate on 329 samples\n",
      "Epoch 1/10\n",
      "2953/2953 [==============================] - 27s - loss: 0.0254 - val_loss: 0.0169\n",
      "Epoch 2/10\n",
      "2953/2953 [==============================] - 23s - loss: 0.0128 - val_loss: 0.0094\n",
      "Epoch 3/10\n",
      "2953/2953 [==============================] - 23s - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 4/10\n",
      "2953/2953 [==============================] - 23s - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 5/10\n",
      "2953/2953 [==============================] - 23s - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "2953/2953 [==============================] - 23s - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "2953/2953 [==============================] - 23s - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "2953/2953 [==============================] - 23s - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 9/10\n",
      "2953/2953 [==============================] - 23s - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 10/10\n",
      "2953/2953 [==============================] - 23s - loss: 0.0059 - val_loss: 0.0057\n",
      "Training duration (s) :  244.68491005897522\n",
      "(3262, 50, 7)\n",
      "(3262, 30)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.024064302444458008\n",
      "Train on 2935 samples, validate on 327 samples\n",
      "Epoch 1/10\n",
      "2935/2935 [==============================] - 27s - loss: 0.0331 - val_loss: 0.0297\n",
      "Epoch 2/10\n",
      "2935/2935 [==============================] - 22s - loss: 0.0223 - val_loss: 0.0172\n",
      "Epoch 3/10\n",
      "2935/2935 [==============================] - 22s - loss: 0.0165 - val_loss: 0.0138\n",
      "Epoch 4/10\n",
      "2935/2935 [==============================] - 22s - loss: 0.0142 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "2935/2935 [==============================] - 22s - loss: 0.0133 - val_loss: 0.0115\n",
      "Epoch 6/10\n",
      "2935/2935 [==============================] - 22s - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 7/10\n",
      "2935/2935 [==============================] - 22s - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 8/10\n",
      "2935/2935 [==============================] - 22s - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 9/10\n",
      "2935/2935 [==============================] - 22s - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 10/10\n",
      "2935/2935 [==============================] - 22s - loss: 0.0112 - val_loss: 0.0105\n",
      "Training duration (s) :  235.55323696136475\n",
      "(3239, 100, 7)\n",
      "(3239, 3)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.02608489990234375\n",
      "Train on 2915 samples, validate on 324 samples\n",
      "Epoch 1/10\n",
      "2915/2915 [==============================] - 46s - loss: 0.0487 - val_loss: 0.0247\n",
      "Epoch 2/10\n",
      "2915/2915 [==============================] - 41s - loss: 0.0162 - val_loss: 0.0102\n",
      "Epoch 3/10\n",
      "2915/2915 [==============================] - 41s - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 4/10\n",
      "2915/2915 [==============================] - 41s - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 5/10\n",
      "2915/2915 [==============================] - 41s - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 6/10\n",
      "2915/2915 [==============================] - 41s - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "2915/2915 [==============================] - 42s - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "2915/2915 [==============================] - 42s - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2915/2915 [==============================] - 42s - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "2915/2915 [==============================] - 42s - loss: 0.0051 - val_loss: 0.0051\n",
      "Training duration (s) :  433.50316429138184\n",
      "(3235, 100, 7)\n",
      "(3235, 7)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.02955174446105957\n",
      "Train on 2911 samples, validate on 324 samples\n",
      "Epoch 1/10\n",
      "2911/2911 [==============================] - 50s - loss: 0.0455 - val_loss: 0.0266\n",
      "Epoch 2/10\n",
      "2911/2911 [==============================] - 45s - loss: 0.0201 - val_loss: 0.0102\n",
      "Epoch 3/10\n",
      "2911/2911 [==============================] - 46s - loss: 0.0117 - val_loss: 0.0076\n",
      "Epoch 4/10\n",
      "2911/2911 [==============================] - 46s - loss: 0.0103 - val_loss: 0.0068\n",
      "Epoch 5/10\n",
      "2911/2911 [==============================] - 46s - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 6/10\n",
      "2911/2911 [==============================] - 46s - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "2911/2911 [==============================] - 47s - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "2911/2911 [==============================] - 46s - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "2911/2911 [==============================] - 47s - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "2911/2911 [==============================] - 47s - loss: 0.0060 - val_loss: 0.0051\n",
      "Training duration (s) :  480.61647748947144\n",
      "(3232, 100, 7)\n",
      "(3232, 10)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.032085418701171875\n",
      "Train on 2908 samples, validate on 324 samples\n",
      "Epoch 1/10\n",
      "2908/2908 [==============================] - 52s - loss: 0.0454 - val_loss: 0.0227\n",
      "Epoch 2/10\n",
      "2908/2908 [==============================] - 48s - loss: 0.0198 - val_loss: 0.0094\n",
      "Epoch 3/10\n",
      "2908/2908 [==============================] - 48s - loss: 0.0124 - val_loss: 0.0066\n",
      "Epoch 4/10\n",
      "2908/2908 [==============================] - 49s - loss: 0.0102 - val_loss: 0.0051\n",
      "Epoch 5/10\n",
      "2908/2908 [==============================] - 48s - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 6/10\n",
      "2908/2908 [==============================] - 48s - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 7/10\n",
      "2908/2908 [==============================] - 49s - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "2908/2908 [==============================] - 49s - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "2908/2908 [==============================] - 49s - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "2908/2908 [==============================] - 49s - loss: 0.0065 - val_loss: 0.0042\n",
      "Training duration (s) :  502.7011594772339\n",
      "(3212, 100, 7)\n",
      "(3212, 30)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.024565458297729492\n",
      "Train on 2890 samples, validate on 322 samples\n",
      "Epoch 1/10\n",
      "2890/2890 [==============================] - 53s - loss: 0.0590 - val_loss: 0.0438\n",
      "Epoch 2/10\n",
      "2890/2890 [==============================] - 48s - loss: 0.0387 - val_loss: 0.0220\n",
      "Epoch 3/10\n",
      "2890/2890 [==============================] - 49s - loss: 0.0228 - val_loss: 0.0141\n",
      "Epoch 4/10\n",
      "2890/2890 [==============================] - 49s - loss: 0.0178 - val_loss: 0.0119\n",
      "Epoch 5/10\n",
      "2890/2890 [==============================] - 49s - loss: 0.0159 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "2890/2890 [==============================] - 49s - loss: 0.0148 - val_loss: 0.0101\n",
      "Epoch 7/10\n",
      "2890/2890 [==============================] - 49s - loss: 0.0139 - val_loss: 0.0096\n",
      "Epoch 8/10\n",
      "2890/2890 [==============================] - 50s - loss: 0.0134 - val_loss: 0.0095\n",
      "Epoch 9/10\n",
      "2890/2890 [==============================] - 50s - loss: 0.0130 - val_loss: 0.0093\n",
      "Epoch 10/10\n",
      "2890/2890 [==============================] - 50s - loss: 0.0127 - val_loss: 0.0091\n",
      "Training duration (s) :  512.0644385814667\n",
      "(3289, 50, 7)\n",
      "(3289, 3)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.024566173553466797\n",
      "Train on 2960 samples, validate on 329 samples\n",
      "Epoch 1/10\n",
      "2960/2960 [==============================] - 34s - loss: 0.0438 - val_loss: 0.0315\n",
      "Epoch 2/10\n",
      "2960/2960 [==============================] - 29s - loss: 0.0188 - val_loss: 0.0161\n",
      "Epoch 3/10\n",
      "2960/2960 [==============================] - 29s - loss: 0.0125 - val_loss: 0.0154\n",
      "Epoch 4/10\n",
      "2960/2960 [==============================] - 29s - loss: 0.0104 - val_loss: 0.0135\n",
      "Epoch 5/10\n",
      "2960/2960 [==============================] - 29s - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 6/10\n",
      "2960/2960 [==============================] - 29s - loss: 0.0083 - val_loss: 0.0117\n",
      "Epoch 7/10\n",
      "2960/2960 [==============================] - 29s - loss: 0.0080 - val_loss: 0.0114\n",
      "Epoch 8/10\n",
      "2960/2960 [==============================] - 29s - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 9/10\n",
      "2960/2960 [==============================] - 29s - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 10/10\n",
      "2960/2960 [==============================] - 29s - loss: 0.0068 - val_loss: 0.0100\n",
      "Training duration (s) :  306.8193247318268\n",
      "(3285, 50, 7)\n",
      "(3285, 7)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.027573347091674805\n",
      "Train on 2956 samples, validate on 329 samples\n",
      "Epoch 1/10\n",
      "2956/2956 [==============================] - 34s - loss: 0.0450 - val_loss: 0.0280\n",
      "Epoch 2/10\n",
      "2956/2956 [==============================] - 29s - loss: 0.0199 - val_loss: 0.0135\n",
      "Epoch 3/10\n",
      "2956/2956 [==============================] - 29s - loss: 0.0152 - val_loss: 0.0112\n",
      "Epoch 4/10\n",
      "2956/2956 [==============================] - 29s - loss: 0.0124 - val_loss: 0.0100\n",
      "Epoch 5/10\n",
      "2956/2956 [==============================] - 29s - loss: 0.0113 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "2956/2956 [==============================] - 29s - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 7/10\n",
      "2956/2956 [==============================] - 29s - loss: 0.0101 - val_loss: 0.0080\n",
      "Epoch 8/10\n",
      "2956/2956 [==============================] - 29s - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 9/10\n",
      "2956/2956 [==============================] - 29s - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 10/10\n",
      "2956/2956 [==============================] - 29s - loss: 0.0087 - val_loss: 0.0067\n",
      "Training duration (s) :  305.6519920825958\n",
      "(3282, 50, 7)\n",
      "(3282, 10)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.026570558547973633\n",
      "Train on 2953 samples, validate on 329 samples\n",
      "Epoch 1/10\n",
      "2953/2953 [==============================] - 33s - loss: 0.0487 - val_loss: 0.0401\n",
      "Epoch 2/10\n",
      "2953/2953 [==============================] - 28s - loss: 0.0276 - val_loss: 0.0180\n",
      "Epoch 3/10\n",
      "2953/2953 [==============================] - 28s - loss: 0.0169 - val_loss: 0.0148\n",
      "Epoch 4/10\n",
      "2953/2953 [==============================] - 28s - loss: 0.0152 - val_loss: 0.0132\n",
      "Epoch 5/10\n",
      "2953/2953 [==============================] - 28s - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 6/10\n",
      "2953/2953 [==============================] - 28s - loss: 0.0123 - val_loss: 0.0114\n",
      "Epoch 7/10\n",
      "2953/2953 [==============================] - 28s - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 8/10\n",
      "2953/2953 [==============================] - 29s - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 9/10\n",
      "2953/2953 [==============================] - 29s - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 10/10\n",
      "2953/2953 [==============================] - 29s - loss: 0.0104 - val_loss: 0.0097\n",
      "Training duration (s) :  303.24231243133545\n",
      "(3262, 50, 7)\n",
      "(3262, 30)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.024063587188720703\n",
      "Train on 2935 samples, validate on 327 samples\n",
      "Epoch 1/10\n",
      "2935/2935 [==============================] - 34s - loss: 0.0704 - val_loss: 0.0534\n",
      "Epoch 2/10\n",
      "2935/2935 [==============================] - 33s - loss: 0.0516 - val_loss: 0.0340\n",
      "Epoch 3/10\n",
      "2935/2935 [==============================] - 30s - loss: 0.0359 - val_loss: 0.0235\n",
      "Epoch 4/10\n",
      "2935/2935 [==============================] - 30s - loss: 0.0280 - val_loss: 0.0212\n",
      "Epoch 5/10\n",
      "2935/2935 [==============================] - 31s - loss: 0.0252 - val_loss: 0.0188\n",
      "Epoch 6/10\n",
      "2935/2935 [==============================] - 32s - loss: 0.0236 - val_loss: 0.0182\n",
      "Epoch 7/10\n",
      "2935/2935 [==============================] - 30s - loss: 0.0226 - val_loss: 0.0180\n",
      "Epoch 8/10\n",
      "2935/2935 [==============================] - 29s - loss: 0.0214 - val_loss: 0.0172\n",
      "Epoch 9/10\n",
      "2935/2935 [==============================] - 31s - loss: 0.0211 - val_loss: 0.0167\n",
      "Epoch 10/10\n",
      "2935/2935 [==============================] - 30s - loss: 0.0207 - val_loss: 0.0163\n",
      "Training duration (s) :  326.76766705513\n",
      "(3239, 100, 7)\n",
      "(3239, 3)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.02606797218322754\n",
      "Train on 2915 samples, validate on 324 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2915/2915 [==============================] - 59s - loss: 0.1020 - val_loss: 0.0467\n",
      "Epoch 2/10\n",
      "2915/2915 [==============================] - 54s - loss: 0.0345 - val_loss: 0.0201\n",
      "Epoch 3/10\n",
      "2915/2915 [==============================] - 55s - loss: 0.0241 - val_loss: 0.0125\n",
      "Epoch 4/10\n",
      "2915/2915 [==============================] - 56s - loss: 0.0187 - val_loss: 0.0129\n",
      "Epoch 5/10\n",
      "2915/2915 [==============================] - 54s - loss: 0.0178 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "2915/2915 [==============================] - 54s - loss: 0.0162 - val_loss: 0.0110\n",
      "Epoch 7/10\n",
      "2915/2915 [==============================] - 54s - loss: 0.0158 - val_loss: 0.0105\n",
      "Epoch 8/10\n",
      "2915/2915 [==============================] - 54s - loss: 0.0150 - val_loss: 0.0102\n",
      "Epoch 9/10\n",
      "2915/2915 [==============================] - 54s - loss: 0.0144 - val_loss: 0.0099\n",
      "Epoch 10/10\n",
      "2915/2915 [==============================] - 54s - loss: 0.0145 - val_loss: 0.0101\n",
      "Training duration (s) :  564.3334879875183\n",
      "(3235, 100, 7)\n",
      "(3235, 7)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.027573823928833008\n",
      "Train on 2911 samples, validate on 324 samples\n",
      "Epoch 1/10\n",
      "2911/2911 [==============================] - 62s - loss: 0.0915 - val_loss: 0.0412\n",
      "Epoch 2/10\n",
      "2911/2911 [==============================] - 56s - loss: 0.0332 - val_loss: 0.0285\n",
      "Epoch 3/10\n",
      "2911/2911 [==============================] - 56s - loss: 0.0251 - val_loss: 0.0261\n",
      "Epoch 4/10\n",
      "2911/2911 [==============================] - 56s - loss: 0.0208 - val_loss: 0.0220\n",
      "Epoch 5/10\n",
      "2911/2911 [==============================] - 56s - loss: 0.0183 - val_loss: 0.0203\n",
      "Epoch 6/10\n",
      "2911/2911 [==============================] - 57s - loss: 0.0169 - val_loss: 0.0198\n",
      "Epoch 7/10\n",
      "2911/2911 [==============================] - 57s - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 8/10\n",
      "2911/2911 [==============================] - 57s - loss: 0.0154 - val_loss: 0.0185\n",
      "Epoch 9/10\n",
      "2911/2911 [==============================] - 58s - loss: 0.0143 - val_loss: 0.0181\n",
      "Epoch 10/10\n",
      "2911/2911 [==============================] - 58s - loss: 0.0142 - val_loss: 0.0176\n",
      "Training duration (s) :  588.3392658233643\n",
      "(3232, 100, 7)\n",
      "(3232, 10)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.026570796966552734\n",
      "Train on 2908 samples, validate on 324 samples\n",
      "Epoch 1/10\n",
      "2908/2908 [==============================] - 64s - loss: 0.1189 - val_loss: 0.0685\n",
      "Epoch 2/10\n",
      "2908/2908 [==============================] - 58s - loss: 0.0518 - val_loss: 0.0315\n",
      "Epoch 3/10\n",
      "2908/2908 [==============================] - 58s - loss: 0.0340 - val_loss: 0.0226\n",
      "Epoch 4/10\n",
      "2908/2908 [==============================] - 58s - loss: 0.0262 - val_loss: 0.0221\n",
      "Epoch 5/10\n",
      "2908/2908 [==============================] - 58s - loss: 0.0230 - val_loss: 0.0199\n",
      "Epoch 6/10\n",
      "2908/2908 [==============================] - 59s - loss: 0.0221 - val_loss: 0.0183\n",
      "Epoch 7/10\n",
      "2908/2908 [==============================] - 58s - loss: 0.0207 - val_loss: 0.0176\n",
      "Epoch 8/10\n",
      "2908/2908 [==============================] - 58s - loss: 0.0201 - val_loss: 0.0172\n",
      "Epoch 9/10\n",
      "2908/2908 [==============================] - 59s - loss: 0.0187 - val_loss: 0.0170\n",
      "Epoch 10/10\n",
      "2908/2908 [==============================] - 59s - loss: 0.0188 - val_loss: 0.0163\n",
      "Training duration (s) :  604.7736518383026\n",
      "(3212, 100, 7)\n",
      "(3212, 30)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.025066614151000977\n",
      "Train on 2890 samples, validate on 322 samples\n",
      "Epoch 1/10\n",
      "2890/2890 [==============================] - 64s - loss: 0.1582 - val_loss: 0.1269\n",
      "Epoch 2/10\n",
      "2890/2890 [==============================] - 59s - loss: 0.0960 - val_loss: 0.0717\n",
      "Epoch 3/10\n",
      "2890/2890 [==============================] - 58s - loss: 0.0579 - val_loss: 0.0556\n",
      "Epoch 4/10\n",
      "2890/2890 [==============================] - 59s - loss: 0.0446 - val_loss: 0.0466\n",
      "Epoch 5/10\n",
      "2890/2890 [==============================] - 59s - loss: 0.0385 - val_loss: 0.0450\n",
      "Epoch 6/10\n",
      "2890/2890 [==============================] - 60s - loss: 0.0342 - val_loss: 0.0412\n",
      "Epoch 7/10\n",
      "2890/2890 [==============================] - 59s - loss: 0.0324 - val_loss: 0.0404\n",
      "Epoch 8/10\n",
      "2890/2890 [==============================] - 60s - loss: 0.0312 - val_loss: 0.0394\n",
      "Epoch 9/10\n",
      "2890/2890 [==============================] - 59s - loss: 0.0304 - val_loss: 0.0380\n",
      "Epoch 10/10\n",
      "2890/2890 [==============================] - 59s - loss: 0.0293 - val_loss: 0.0372\n",
      "Training duration (s) :  613.2263395786285\n",
      "(2615, 50, 7)\n",
      "(2615, 3)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.024593114852905273\n",
      "Train on 2353 samples, validate on 262 samples\n",
      "Epoch 1/10\n",
      "2353/2353 [==============================] - 32s - loss: 0.0472 - val_loss: 0.0265\n",
      "Epoch 2/10\n",
      "2353/2353 [==============================] - 26s - loss: 0.0210 - val_loss: 0.0133\n",
      "Epoch 3/10\n",
      "2353/2353 [==============================] - 26s - loss: 0.0160 - val_loss: 0.0110\n",
      "Epoch 4/10\n",
      "2353/2353 [==============================] - 26s - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 5/10\n",
      "2353/2353 [==============================] - 26s - loss: 0.0112 - val_loss: 0.0094\n",
      "Epoch 6/10\n",
      "2353/2353 [==============================] - 26s - loss: 0.0096 - val_loss: 0.0086\n",
      "Epoch 7/10\n",
      "2353/2353 [==============================] - 26s - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 8/10\n",
      "2353/2353 [==============================] - 26s - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 9/10\n",
      "2353/2353 [==============================] - 26s - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 10/10\n",
      "2353/2353 [==============================] - 25s - loss: 0.0075 - val_loss: 0.0070\n",
      "Training duration (s) :  276.0988025665283\n",
      "(2611, 50, 7)\n",
      "(2611, 7)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.025567054748535156\n",
      "Train on 2349 samples, validate on 262 samples\n",
      "Epoch 1/10\n",
      "2349/2349 [==============================] - 32s - loss: 0.0487 - val_loss: 0.0256\n",
      "Epoch 2/10\n",
      "2349/2349 [==============================] - 26s - loss: 0.0253 - val_loss: 0.0153\n",
      "Epoch 3/10\n",
      "2349/2349 [==============================] - 25s - loss: 0.0180 - val_loss: 0.0102\n",
      "Epoch 4/10\n",
      "2349/2349 [==============================] - 26s - loss: 0.0154 - val_loss: 0.0092\n",
      "Epoch 5/10\n",
      "2349/2349 [==============================] - 25s - loss: 0.0140 - val_loss: 0.0088\n",
      "Epoch 6/10\n",
      "2349/2349 [==============================] - 26s - loss: 0.0124 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "2349/2349 [==============================] - 25s - loss: 0.0117 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "2349/2349 [==============================] - 25s - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 9/10\n",
      "2349/2349 [==============================] - 25s - loss: 0.0103 - val_loss: 0.0075\n",
      "Epoch 10/10\n",
      "2349/2349 [==============================] - 25s - loss: 0.0093 - val_loss: 0.0066\n",
      "Training duration (s) :  274.405962228775\n",
      "(2608, 50, 7)\n",
      "(2608, 10)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.02506709098815918\n",
      "Train on 2347 samples, validate on 261 samples\n",
      "Epoch 1/10\n",
      "2347/2347 [==============================] - 33s - loss: 0.0596 - val_loss: 0.0369\n",
      "Epoch 2/10\n",
      "2347/2347 [==============================] - 27s - loss: 0.0354 - val_loss: 0.0192\n",
      "Epoch 3/10\n",
      "2347/2347 [==============================] - 26s - loss: 0.0219 - val_loss: 0.0160\n",
      "Epoch 4/10\n",
      "2347/2347 [==============================] - 26s - loss: 0.0174 - val_loss: 0.0137\n",
      "Epoch 5/10\n",
      "2347/2347 [==============================] - 27s - loss: 0.0157 - val_loss: 0.0126\n",
      "Epoch 6/10\n",
      "2347/2347 [==============================] - 27s - loss: 0.0139 - val_loss: 0.0114\n",
      "Epoch 7/10\n",
      "2347/2347 [==============================] - 26s - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 8/10\n",
      "2347/2347 [==============================] - 26s - loss: 0.0119 - val_loss: 0.0104\n",
      "Epoch 9/10\n",
      "2347/2347 [==============================] - 27s - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 10/10\n",
      "2347/2347 [==============================] - 26s - loss: 0.0107 - val_loss: 0.0089\n",
      "Training duration (s) :  291.3224368095398\n",
      "(2588, 50, 7)\n",
      "(2588, 30)\n",
      "(1, 50, 7)\n",
      "> Compilation Time :  0.026570558547973633\n",
      "Train on 2329 samples, validate on 259 samples\n",
      "Epoch 1/10\n",
      "2329/2329 [==============================] - 32s - loss: 0.0771 - val_loss: 0.0634\n",
      "Epoch 2/10\n",
      "2329/2329 [==============================] - 26s - loss: 0.0649 - val_loss: 0.0519\n",
      "Epoch 3/10\n",
      "2329/2329 [==============================] - 26s - loss: 0.0509 - val_loss: 0.0354\n",
      "Epoch 4/10\n",
      "2329/2329 [==============================] - 26s - loss: 0.0371 - val_loss: 0.0257\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2329/2329 [==============================] - 26s - loss: 0.0293 - val_loss: 0.0231\n",
      "Epoch 6/10\n",
      "2329/2329 [==============================] - 26s - loss: 0.0266 - val_loss: 0.0211\n",
      "Epoch 7/10\n",
      "2329/2329 [==============================] - 26s - loss: 0.0243 - val_loss: 0.0195\n",
      "Epoch 8/10\n",
      "2329/2329 [==============================] - 26s - loss: 0.0227 - val_loss: 0.0190\n",
      "Epoch 9/10\n",
      "2329/2329 [==============================] - 26s - loss: 0.0216 - val_loss: 0.0183\n",
      "Epoch 10/10\n",
      "2329/2329 [==============================] - 26s - loss: 0.0213 - val_loss: 0.0181\n",
      "Training duration (s) :  279.550852060318\n",
      "(2565, 100, 7)\n",
      "(2565, 3)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.024590730667114258\n",
      "Train on 2308 samples, validate on 257 samples\n",
      "Epoch 1/10\n",
      "2308/2308 [==============================] - 54s - loss: 0.0816 - val_loss: 0.0341\n",
      "Epoch 2/10\n",
      "2308/2308 [==============================] - 48s - loss: 0.0298 - val_loss: 0.0253\n",
      "Epoch 3/10\n",
      "2308/2308 [==============================] - 49s - loss: 0.0240 - val_loss: 0.0152\n",
      "Epoch 4/10\n",
      "2308/2308 [==============================] - 49s - loss: 0.0182 - val_loss: 0.0135\n",
      "Epoch 5/10\n",
      "2308/2308 [==============================] - 49s - loss: 0.0162 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "2308/2308 [==============================] - 49s - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "2308/2308 [==============================] - 50s - loss: 0.0132 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "2308/2308 [==============================] - 50s - loss: 0.0122 - val_loss: 0.0081\n",
      "Epoch 9/10\n",
      "2308/2308 [==============================] - 50s - loss: 0.0107 - val_loss: 0.0078\n",
      "Epoch 10/10\n",
      "2308/2308 [==============================] - 50s - loss: 0.0103 - val_loss: 0.0073\n",
      "Training duration (s) :  514.0296332836151\n",
      "(2561, 100, 7)\n",
      "(2561, 7)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.026079416275024414\n",
      "Train on 2304 samples, validate on 257 samples\n",
      "Epoch 1/10\n",
      "2304/2304 [==============================] - 57s - loss: 0.1232 - val_loss: 0.0729\n",
      "Epoch 2/10\n",
      "2304/2304 [==============================] - 50s - loss: 0.0592 - val_loss: 0.0400\n",
      "Epoch 3/10\n",
      "2304/2304 [==============================] - 51s - loss: 0.0373 - val_loss: 0.0315\n",
      "Epoch 4/10\n",
      "2304/2304 [==============================] - 51s - loss: 0.0268 - val_loss: 0.0246\n",
      "Epoch 5/10\n",
      "2304/2304 [==============================] - 51s - loss: 0.0230 - val_loss: 0.0227\n",
      "Epoch 6/10\n",
      "2304/2304 [==============================] - 51s - loss: 0.0211 - val_loss: 0.0205\n",
      "Epoch 7/10\n",
      "2304/2304 [==============================] - 51s - loss: 0.0184 - val_loss: 0.0181\n",
      "Epoch 8/10\n",
      "2304/2304 [==============================] - 51s - loss: 0.0169 - val_loss: 0.0160\n",
      "Epoch 9/10\n",
      "2304/2304 [==============================] - 52s - loss: 0.0160 - val_loss: 0.0136\n",
      "Epoch 10/10\n",
      "2304/2304 [==============================] - 52s - loss: 0.0147 - val_loss: 0.0124\n",
      "Training duration (s) :  532.5456025600433\n",
      "(2558, 100, 7)\n",
      "(2558, 10)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.025569677352905273\n",
      "Train on 2302 samples, validate on 256 samples\n",
      "Epoch 1/10\n",
      "2302/2302 [==============================] - 59s - loss: 0.1302 - val_loss: 0.0972\n",
      "Epoch 2/10\n",
      "2302/2302 [==============================] - 53s - loss: 0.0694 - val_loss: 0.0336\n",
      "Epoch 3/10\n",
      "2302/2302 [==============================] - 53s - loss: 0.0408 - val_loss: 0.0226\n",
      "Epoch 4/10\n",
      "2302/2302 [==============================] - 53s - loss: 0.0324 - val_loss: 0.0231\n",
      "Epoch 5/10\n",
      "2302/2302 [==============================] - 54s - loss: 0.0289 - val_loss: 0.0213\n",
      "Epoch 6/10\n",
      "2302/2302 [==============================] - 54s - loss: 0.0250 - val_loss: 0.0187\n",
      "Epoch 7/10\n",
      "2302/2302 [==============================] - 54s - loss: 0.0237 - val_loss: 0.0165\n",
      "Epoch 8/10\n",
      "2302/2302 [==============================] - 54s - loss: 0.0214 - val_loss: 0.0153\n",
      "Epoch 9/10\n",
      "2302/2302 [==============================] - 55s - loss: 0.0196 - val_loss: 0.0143\n",
      "Epoch 10/10\n",
      "2302/2302 [==============================] - 55s - loss: 0.0178 - val_loss: 0.0125\n",
      "Training duration (s) :  559.1353957653046\n",
      "(2538, 100, 7)\n",
      "(2538, 30)\n",
      "(1, 100, 7)\n",
      "> Compilation Time :  0.024063587188720703\n",
      "Train on 2284 samples, validate on 254 samples\n",
      "Epoch 1/10\n",
      "2284/2284 [==============================] - 60s - loss: 0.1456 - val_loss: 0.1261\n",
      "Epoch 2/10\n",
      "2284/2284 [==============================] - 53s - loss: 0.1028 - val_loss: 0.0737\n",
      "Epoch 3/10\n",
      "2284/2284 [==============================] - 54s - loss: 0.0637 - val_loss: 0.0563\n",
      "Epoch 4/10\n",
      "2284/2284 [==============================] - 54s - loss: 0.0489 - val_loss: 0.0454\n",
      "Epoch 5/10\n",
      "2284/2284 [==============================] - 54s - loss: 0.0408 - val_loss: 0.0392\n",
      "Epoch 6/10\n",
      "2284/2284 [==============================] - 54s - loss: 0.0360 - val_loss: 0.0355\n",
      "Epoch 7/10\n",
      "2284/2284 [==============================] - 54s - loss: 0.0329 - val_loss: 0.0319\n",
      "Epoch 8/10\n",
      "2284/2284 [==============================] - 55s - loss: 0.0303 - val_loss: 0.0301\n",
      "Epoch 9/10\n",
      "2284/2284 [==============================] - 54s - loss: 0.0281 - val_loss: 0.0280\n",
      "Epoch 10/10\n",
      "2284/2284 [==============================] - 54s - loss: 0.0268 - val_loss: 0.0264\n",
      "Training duration (s) :  560.8111214637756\n",
      "Total training duration (s) :  14471.792671442032\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lstm\n",
    "import time\n",
    "import h5py\n",
    "\n",
    "ModelInformation = pd.read_pickle(\"../model/ModelInformation.pickle\")\n",
    "columns = ModelInformation.columns\n",
    "global_start_time = time.time()\n",
    "for i in range(len(ModelInformation)):\n",
    "    forloop_start_time = time.time()\n",
    "    #\n",
    "    Filename = ModelInformation.loc[i,columns[0]]\n",
    "    ColumnList = ModelInformation.loc[i,columns[1]]\n",
    "    WindowSize = ModelInformation.loc[i,columns[2]]\n",
    "    NumOfPredictDay = ModelInformation.loc[i,columns[3]]\n",
    "    \n",
    "    print('Train the ' + str(i) + '.h5 model')\n",
    "    \n",
    "    #\n",
    "    DataSet = lstm.LoadData(Filename, ColumnList, WindowSize, NumOfPredictDay)\n",
    "    #\n",
    "    NormalizeData = lstm.NormaliseWindows(DataSet)\n",
    "    #\n",
    "    #x_train, y_train, x_test, y_test = lstm.SplitData(NormalizeData, ColumnList, NumOfPredictDay)\n",
    "    #sequence_length = WindowSize + NumOfPredictDay\n",
    "\n",
    "    #\n",
    "    x_train, y_train = lstm.SplitDatatoTrain(NormalizeData, ColumnList, NumOfPredictDay)\n",
    "    #\n",
    "    x_predict = lstm.SplitDatatoPredict(DataSet, ColumnList, NumOfPredictDay)\n",
    "    x_predict = lstm.NormaliseWindows(x_predict)\n",
    "    \n",
    "    #\n",
    "    Layer = ModelInformation.loc[i,columns[4]]\n",
    "    Loss = ModelInformation.loc[i,columns[5]]\n",
    "    Optimizer = ModelInformation.loc[i,columns[6]]\n",
    "    \n",
    "    #LSTM\n",
    "    model = lstm.build_model(Layer,Loss,Optimizer)\n",
    "    \n",
    "    #\n",
    "    BatchSize = ModelInformation.loc[i,columns[7]]\n",
    "    Epoch = ModelInformation.loc[i,columns[8]]\n",
    "    ValidationSplit = ModelInformation.loc[i,columns[9]]\n",
    "    \n",
    "    #LSTM\n",
    "    model.fit(  x_train,\n",
    "                y_train,\n",
    "                batch_size=BatchSize,\n",
    "                nb_epoch=Epoch,\n",
    "                validation_split=ValidationSplit)\n",
    "    \n",
    "    #\n",
    "    ModelName = ModelInformation.loc[i,columns[10]]\n",
    "    \n",
    "    #HDF5, pip3\n",
    "    model.save('../model/' + ModelName)\n",
    "    print('Training duration (s) : ',time.time() - forloop_start_time)\n",
    "\n",
    "print('Total training duration (s) : ',time.time() - global_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2537, 100, 7)\n",
      "(2537, 30)\n",
      "(1, 100, 7)\n",
      "(30, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njDEb/wf3kk4c0dBn5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x294620dacc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = lstm.SplitDatatoTest(NormalizeData, ColumnList, NumOfPredictDay)\n",
    "#\n",
    "predictions = lstm.predict_point_by_point(model, x_test)\n",
    "lstm.plot_predict(predictions, NumOfPredictDay, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
